{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385eb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kagglehub\n",
    "# ! pip3 install torch torchvision\n",
    "# ! pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu129 --verbose\n",
    "\n",
    "# ! pip3 uninstall -y torch torchvision torchaudio\n",
    "# ! pip3 cache purge\n",
    "# ! pip list\n",
    "# ! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a1dea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu129\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "destination_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "destination_path = 'D' + destination_path[1:] + r'\\KC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d982a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Download latest version\n",
    "    source_path = kagglehub.dataset_download(\"ryanholbrook/car-or-truck\")\n",
    "    #destination_path = r\"D:\\Users\\fejio\\Downloads\\KC\"\n",
    "    print(\"Path to dataset files:\", source_path)\n",
    "\n",
    "    os.makedirs(destination_path, exist_ok=True)\n",
    "    # shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
    "    shutil.move(source_path, destination_path)\n",
    "    print(\"Dataset copied to:\", destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bffe191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size must match target_size=(64,64)\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Training data augmentations (same as ImageDataGenerator)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomAffine(degrees=0, shear=20),   # shear_range=0.2\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.2)), # zoom_range\n",
    "    transforms.RandomHorizontalFlip(p=0.5),         # horizontal_flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # rescale=1./255 equivalent\n",
    "])\n",
    "\n",
    "# Validation data (only rescaling)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "destination_path_1 = destination_path + r'\\1'\n",
    "\n",
    "# Datasets (folder structure must be same as Keras: class subfolders inside train/valid)\n",
    "train_dataset = datasets.ImageFolder(root=destination_path_1 + r\"\\train\", transform=train_transform)\n",
    "test_dataset =  datasets.ImageFolder(root=destination_path_1 + r\"\\valid\", transform=test_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19961526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Example: iterate\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0f7be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model_state = model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c64e8c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolution layer 1\n",
    "        # input_shape = [64, 64, 3] â†’ in_channels=3\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=1)  # pool_size=2, strides=1\n",
    "        \n",
    "        # Convolution layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # pool_size=2, strides=2\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Connection layers\n",
    "        self.fc1 = nn.Linear(1, 200)  # must compute flattened size\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 1)  # output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Convolution layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten Layer\n",
    "        x = self.flatten(x)\n",
    "        # Initialize fc1 dynamically on first forward pass\n",
    "        if self.fc1.in_features == 1:\n",
    "            self.fc1 = nn.Linear(x.shape[1], 200).to(x.device)\n",
    "\n",
    "        # Connection layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = torch.sigmoid(self.fc3(x))  # sigmoid like Keras\n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "model = CNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4abf9ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/150] Train Loss: 0.6645, Train Acc: 59.53% | Val Loss: 0.6448, Val Acc: 61.91%\n",
      "Epoch [2/150] Train Loss: 0.6325, Train Acc: 63.90% | Val Loss: 0.6202, Val Acc: 64.76%\n",
      "Epoch [3/150] Train Loss: 0.6268, Train Acc: 64.20% | Val Loss: 0.6161, Val Acc: 66.52%\n",
      "Epoch [4/150] Train Loss: 0.6208, Train Acc: 65.06% | Val Loss: 0.6078, Val Acc: 66.70%\n",
      "Epoch [5/150] Train Loss: 0.6132, Train Acc: 65.94% | Val Loss: 0.6078, Val Acc: 66.68%\n",
      "Epoch [6/150] Train Loss: 0.6114, Train Acc: 66.07% | Val Loss: 0.6135, Val Acc: 65.85%\n",
      "Epoch [7/150] Train Loss: 0.6122, Train Acc: 66.02% | Val Loss: 0.6033, Val Acc: 67.16%\n",
      "Epoch [8/150] Train Loss: 0.6097, Train Acc: 66.19% | Val Loss: 0.6019, Val Acc: 67.35%\n",
      "Epoch [9/150] Train Loss: 0.6045, Train Acc: 66.50% | Val Loss: 0.5969, Val Acc: 68.03%\n",
      "Epoch [10/150] Train Loss: 0.5977, Train Acc: 67.29% | Val Loss: 0.5997, Val Acc: 68.09%\n",
      "Epoch [11/150] Train Loss: 0.5975, Train Acc: 67.56% | Val Loss: 0.5930, Val Acc: 68.09%\n",
      "Epoch [12/150] Train Loss: 0.5922, Train Acc: 67.58% | Val Loss: 0.6058, Val Acc: 66.66%\n",
      "Epoch [13/150] Train Loss: 0.5934, Train Acc: 67.91% | Val Loss: 0.5929, Val Acc: 68.60%\n",
      "Epoch [14/150] Train Loss: 0.5894, Train Acc: 68.36% | Val Loss: 0.5836, Val Acc: 69.37%\n",
      "Epoch [15/150] Train Loss: 0.5891, Train Acc: 68.89% | Val Loss: 0.5839, Val Acc: 69.08%\n",
      "Epoch [16/150] Train Loss: 0.5891, Train Acc: 68.54% | Val Loss: 0.5847, Val Acc: 68.56%\n",
      "Epoch [17/150] Train Loss: 0.5842, Train Acc: 68.75% | Val Loss: 0.5901, Val Acc: 68.18%\n",
      "Epoch [18/150] Train Loss: 0.5846, Train Acc: 68.18% | Val Loss: 0.5795, Val Acc: 69.39%\n",
      "Epoch [19/150] Train Loss: 0.5804, Train Acc: 69.12% | Val Loss: 0.5875, Val Acc: 68.88%\n",
      "Epoch [20/150] Train Loss: 0.5785, Train Acc: 69.94% | Val Loss: 0.5941, Val Acc: 67.79%\n",
      "Epoch [21/150] Train Loss: 0.5757, Train Acc: 69.57% | Val Loss: 0.5868, Val Acc: 68.74%\n",
      "Epoch [22/150] Train Loss: 0.5678, Train Acc: 69.71% | Val Loss: 0.5842, Val Acc: 68.58%\n",
      "Epoch [23/150] Train Loss: 0.5705, Train Acc: 70.43% | Val Loss: 0.5740, Val Acc: 70.05%\n",
      "Epoch [24/150] Train Loss: 0.5740, Train Acc: 69.51% | Val Loss: 0.5724, Val Acc: 70.14%\n",
      "Epoch [25/150] Train Loss: 0.5666, Train Acc: 69.69% | Val Loss: 0.5751, Val Acc: 69.99%\n",
      "Epoch [26/150] Train Loss: 0.5661, Train Acc: 70.10% | Val Loss: 0.5741, Val Acc: 70.09%\n",
      "Epoch [27/150] Train Loss: 0.5694, Train Acc: 69.75% | Val Loss: 0.5676, Val Acc: 70.42%\n",
      "Epoch [28/150] Train Loss: 0.5627, Train Acc: 70.94% | Val Loss: 0.5959, Val Acc: 67.67%\n",
      "Epoch [29/150] Train Loss: 0.5591, Train Acc: 70.76% | Val Loss: 0.5770, Val Acc: 70.44%\n",
      "Epoch [30/150] Train Loss: 0.5631, Train Acc: 70.26% | Val Loss: 0.5663, Val Acc: 70.94%\n",
      "Epoch [31/150] Train Loss: 0.5553, Train Acc: 71.10% | Val Loss: 0.5658, Val Acc: 70.94%\n",
      "Epoch [32/150] Train Loss: 0.5568, Train Acc: 70.92% | Val Loss: 0.5695, Val Acc: 70.36%\n",
      "Epoch [33/150] Train Loss: 0.5613, Train Acc: 70.59% | Val Loss: 0.5648, Val Acc: 70.90%\n",
      "Epoch [34/150] Train Loss: 0.5565, Train Acc: 70.76% | Val Loss: 0.5669, Val Acc: 70.56%\n",
      "Epoch [35/150] Train Loss: 0.5529, Train Acc: 70.30% | Val Loss: 0.5692, Val Acc: 70.88%\n",
      "Epoch [36/150] Train Loss: 0.5504, Train Acc: 71.72% | Val Loss: 0.5643, Val Acc: 70.96%\n",
      "Epoch [37/150] Train Loss: 0.5435, Train Acc: 71.86% | Val Loss: 0.5616, Val Acc: 71.35%\n",
      "Epoch [38/150] Train Loss: 0.5487, Train Acc: 71.94% | Val Loss: 0.5692, Val Acc: 70.64%\n",
      "Epoch [39/150] Train Loss: 0.5451, Train Acc: 71.51% | Val Loss: 0.5585, Val Acc: 71.04%\n",
      "Epoch [40/150] Train Loss: 0.5441, Train Acc: 71.58% | Val Loss: 0.5504, Val Acc: 72.48%\n",
      "Epoch [41/150] Train Loss: 0.5529, Train Acc: 71.82% | Val Loss: 0.5606, Val Acc: 71.19%\n",
      "Epoch [42/150] Train Loss: 0.5434, Train Acc: 71.53% | Val Loss: 0.5486, Val Acc: 72.12%\n",
      "Epoch [43/150] Train Loss: 0.5384, Train Acc: 71.47% | Val Loss: 0.5650, Val Acc: 70.72%\n",
      "Epoch [44/150] Train Loss: 0.5409, Train Acc: 72.66% | Val Loss: 0.5564, Val Acc: 71.53%\n",
      "Epoch [45/150] Train Loss: 0.5435, Train Acc: 71.66% | Val Loss: 0.5460, Val Acc: 72.24%\n",
      "Epoch [46/150] Train Loss: 0.5341, Train Acc: 72.72% | Val Loss: 0.5466, Val Acc: 72.54%\n",
      "Epoch [47/150] Train Loss: 0.5347, Train Acc: 72.54% | Val Loss: 0.5599, Val Acc: 71.55%\n",
      "Epoch [48/150] Train Loss: 0.5349, Train Acc: 72.39% | Val Loss: 0.5410, Val Acc: 72.80%\n",
      "Epoch [49/150] Train Loss: 0.5285, Train Acc: 72.80% | Val Loss: 0.5499, Val Acc: 71.99%\n",
      "Epoch [50/150] Train Loss: 0.5259, Train Acc: 73.34% | Val Loss: 0.5491, Val Acc: 71.83%\n",
      "Epoch [51/150] Train Loss: 0.5299, Train Acc: 72.95% | Val Loss: 0.5571, Val Acc: 71.81%\n",
      "Epoch [52/150] Train Loss: 0.5215, Train Acc: 73.79% | Val Loss: 0.5511, Val Acc: 72.14%\n",
      "Epoch [53/150] Train Loss: 0.5145, Train Acc: 73.75% | Val Loss: 0.5528, Val Acc: 73.15%\n",
      "Epoch [54/150] Train Loss: 0.5220, Train Acc: 73.17% | Val Loss: 0.5890, Val Acc: 69.61%\n",
      "Epoch [55/150] Train Loss: 0.5226, Train Acc: 73.50% | Val Loss: 0.5525, Val Acc: 71.73%\n",
      "Epoch [56/150] Train Loss: 0.5165, Train Acc: 74.18% | Val Loss: 0.5475, Val Acc: 73.07%\n",
      "Epoch [57/150] Train Loss: 0.5145, Train Acc: 74.61% | Val Loss: 0.6109, Val Acc: 69.45%\n",
      "Epoch [58/150] Train Loss: 0.5108, Train Acc: 74.50% | Val Loss: 0.5384, Val Acc: 73.69%\n",
      "Epoch [59/150] Train Loss: 0.5114, Train Acc: 75.10% | Val Loss: 0.5526, Val Acc: 71.97%\n",
      "Epoch [60/150] Train Loss: 0.5186, Train Acc: 73.40% | Val Loss: 0.5322, Val Acc: 73.97%\n",
      "Epoch [61/150] Train Loss: 0.5131, Train Acc: 74.44% | Val Loss: 0.5401, Val Acc: 73.59%\n",
      "Epoch [62/150] Train Loss: 0.5139, Train Acc: 74.71% | Val Loss: 0.5464, Val Acc: 73.13%\n",
      "Epoch [63/150] Train Loss: 0.5000, Train Acc: 75.02% | Val Loss: 0.5601, Val Acc: 73.11%\n",
      "Epoch [64/150] Train Loss: 0.5051, Train Acc: 74.89% | Val Loss: 0.5511, Val Acc: 72.86%\n",
      "Epoch [65/150] Train Loss: 0.5065, Train Acc: 74.52% | Val Loss: 0.5452, Val Acc: 73.15%\n",
      "Epoch [66/150] Train Loss: 0.5084, Train Acc: 75.08% | Val Loss: 0.5343, Val Acc: 73.77%\n",
      "Epoch [67/150] Train Loss: 0.5111, Train Acc: 74.01% | Val Loss: 0.5578, Val Acc: 72.48%\n",
      "Epoch [68/150] Train Loss: 0.5043, Train Acc: 75.06% | Val Loss: 0.5553, Val Acc: 72.82%\n",
      "Epoch [69/150] Train Loss: 0.5044, Train Acc: 74.67% | Val Loss: 0.5328, Val Acc: 73.31%\n",
      "Epoch [70/150] Train Loss: 0.5020, Train Acc: 74.40% | Val Loss: 0.5591, Val Acc: 73.23%\n",
      "Epoch [71/150] Train Loss: 0.5024, Train Acc: 75.06% | Val Loss: 0.5313, Val Acc: 74.02%\n",
      "Epoch [72/150] Train Loss: 0.5096, Train Acc: 73.91% | Val Loss: 0.5325, Val Acc: 74.12%\n",
      "Epoch [73/150] Train Loss: 0.5051, Train Acc: 74.57% | Val Loss: 0.5411, Val Acc: 73.63%\n",
      "Epoch [74/150] Train Loss: 0.4996, Train Acc: 75.49% | Val Loss: 0.5335, Val Acc: 74.14%\n",
      "Epoch [75/150] Train Loss: 0.4932, Train Acc: 75.57% | Val Loss: 0.5385, Val Acc: 74.14%\n",
      "Epoch [76/150] Train Loss: 0.4895, Train Acc: 75.43% | Val Loss: 0.5626, Val Acc: 72.48%\n",
      "Epoch [77/150] Train Loss: 0.4938, Train Acc: 75.14% | Val Loss: 0.5361, Val Acc: 74.34%\n",
      "Epoch [78/150] Train Loss: 0.4893, Train Acc: 76.16% | Val Loss: 0.5402, Val Acc: 73.67%\n",
      "Epoch [79/150] Train Loss: 0.4969, Train Acc: 75.14% | Val Loss: 0.5391, Val Acc: 73.67%\n",
      "Epoch [80/150] Train Loss: 0.4861, Train Acc: 76.55% | Val Loss: 0.5229, Val Acc: 75.11%\n",
      "Epoch [81/150] Train Loss: 0.4937, Train Acc: 75.00% | Val Loss: 0.5495, Val Acc: 73.11%\n",
      "Epoch [82/150] Train Loss: 0.4729, Train Acc: 76.67% | Val Loss: 0.5447, Val Acc: 74.10%\n",
      "Epoch [83/150] Train Loss: 0.4837, Train Acc: 76.28% | Val Loss: 0.5359, Val Acc: 74.48%\n",
      "Epoch [84/150] Train Loss: 0.4793, Train Acc: 76.14% | Val Loss: 0.5288, Val Acc: 74.58%\n",
      "Epoch [85/150] Train Loss: 0.4705, Train Acc: 77.00% | Val Loss: 0.5412, Val Acc: 73.67%\n",
      "Epoch [86/150] Train Loss: 0.4827, Train Acc: 76.12% | Val Loss: 0.5392, Val Acc: 73.99%\n",
      "Epoch [87/150] Train Loss: 0.4759, Train Acc: 76.39% | Val Loss: 0.5510, Val Acc: 73.19%\n",
      "Epoch [88/150] Train Loss: 0.4735, Train Acc: 77.02% | Val Loss: 0.5361, Val Acc: 74.14%\n",
      "Epoch [89/150] Train Loss: 0.4766, Train Acc: 76.41% | Val Loss: 0.5352, Val Acc: 73.97%\n",
      "Epoch [90/150] Train Loss: 0.4808, Train Acc: 76.78% | Val Loss: 0.5795, Val Acc: 72.54%\n",
      "Epoch [91/150] Train Loss: 0.4789, Train Acc: 76.96% | Val Loss: 0.5217, Val Acc: 75.39%\n",
      "Epoch [92/150] Train Loss: 0.4724, Train Acc: 77.23% | Val Loss: 0.5404, Val Acc: 73.25%\n",
      "Epoch [93/150] Train Loss: 0.4763, Train Acc: 76.33% | Val Loss: 0.5371, Val Acc: 74.12%\n",
      "Epoch [94/150] Train Loss: 0.4823, Train Acc: 76.35% | Val Loss: 0.5303, Val Acc: 73.93%\n",
      "Epoch [95/150] Train Loss: 0.4582, Train Acc: 78.25% | Val Loss: 0.5376, Val Acc: 74.14%\n",
      "Epoch [96/150] Train Loss: 0.4738, Train Acc: 77.23% | Val Loss: 0.5454, Val Acc: 73.77%\n",
      "Epoch [97/150] Train Loss: 0.4621, Train Acc: 78.01% | Val Loss: 0.5505, Val Acc: 74.36%\n",
      "Epoch [98/150] Train Loss: 0.4694, Train Acc: 77.00% | Val Loss: 0.5457, Val Acc: 73.71%\n",
      "Epoch [99/150] Train Loss: 0.4691, Train Acc: 77.08% | Val Loss: 0.5394, Val Acc: 74.78%\n",
      "Epoch [100/150] Train Loss: 0.4704, Train Acc: 77.17% | Val Loss: 0.5317, Val Acc: 75.00%\n",
      "Epoch [101/150] Train Loss: 0.4763, Train Acc: 76.72% | Val Loss: 0.5542, Val Acc: 73.35%\n",
      "Epoch [102/150] Train Loss: 0.4754, Train Acc: 77.27% | Val Loss: 0.5287, Val Acc: 74.94%\n",
      "Epoch [103/150] Train Loss: 0.4737, Train Acc: 76.90% | Val Loss: 0.5445, Val Acc: 73.93%\n",
      "Epoch [104/150] Train Loss: 0.4639, Train Acc: 77.58% | Val Loss: 0.5388, Val Acc: 74.92%\n",
      "Epoch [105/150] Train Loss: 0.4640, Train Acc: 77.17% | Val Loss: 0.5400, Val Acc: 74.40%\n",
      "Epoch [106/150] Train Loss: 0.4695, Train Acc: 77.62% | Val Loss: 0.5381, Val Acc: 74.86%\n",
      "Epoch [107/150] Train Loss: 0.4679, Train Acc: 77.27% | Val Loss: 0.5203, Val Acc: 75.55%\n",
      "Epoch [108/150] Train Loss: 0.4537, Train Acc: 78.21% | Val Loss: 0.5412, Val Acc: 74.16%\n",
      "Epoch [109/150] Train Loss: 0.4662, Train Acc: 77.37% | Val Loss: 0.5483, Val Acc: 73.71%\n",
      "Epoch [110/150] Train Loss: 0.4513, Train Acc: 78.72% | Val Loss: 0.5214, Val Acc: 74.86%\n",
      "Epoch [111/150] Train Loss: 0.4514, Train Acc: 78.27% | Val Loss: 0.5751, Val Acc: 71.53%\n",
      "Epoch [112/150] Train Loss: 0.4533, Train Acc: 78.27% | Val Loss: 0.5307, Val Acc: 74.88%\n",
      "Epoch [113/150] Train Loss: 0.4565, Train Acc: 78.33% | Val Loss: 0.5251, Val Acc: 74.50%\n",
      "Epoch [114/150] Train Loss: 0.4520, Train Acc: 78.62% | Val Loss: 0.5457, Val Acc: 74.20%\n",
      "Epoch [115/150] Train Loss: 0.4568, Train Acc: 78.19% | Val Loss: 0.5434, Val Acc: 75.17%\n",
      "Epoch [116/150] Train Loss: 0.4536, Train Acc: 77.99% | Val Loss: 0.5357, Val Acc: 74.60%\n",
      "Epoch [117/150] Train Loss: 0.4633, Train Acc: 77.51% | Val Loss: 0.5343, Val Acc: 74.28%\n",
      "Epoch [118/150] Train Loss: 0.4561, Train Acc: 78.15% | Val Loss: 0.5413, Val Acc: 73.63%\n",
      "Epoch [119/150] Train Loss: 0.4582, Train Acc: 77.39% | Val Loss: 0.5231, Val Acc: 74.38%\n",
      "Epoch [120/150] Train Loss: 0.4632, Train Acc: 77.43% | Val Loss: 0.5485, Val Acc: 72.30%\n",
      "Epoch [121/150] Train Loss: 0.4467, Train Acc: 78.93% | Val Loss: 0.5465, Val Acc: 74.50%\n",
      "Epoch [122/150] Train Loss: 0.4447, Train Acc: 79.05% | Val Loss: 0.5251, Val Acc: 75.31%\n",
      "Epoch [123/150] Train Loss: 0.4568, Train Acc: 77.96% | Val Loss: 0.5291, Val Acc: 75.39%\n",
      "Epoch [124/150] Train Loss: 0.4488, Train Acc: 78.39% | Val Loss: 0.5369, Val Acc: 74.60%\n",
      "Epoch [125/150] Train Loss: 0.4481, Train Acc: 78.39% | Val Loss: 0.5277, Val Acc: 74.96%\n",
      "Epoch [126/150] Train Loss: 0.4443, Train Acc: 79.07% | Val Loss: 0.5342, Val Acc: 74.88%\n",
      "Epoch [127/150] Train Loss: 0.4363, Train Acc: 79.11% | Val Loss: 0.5426, Val Acc: 73.95%\n",
      "Epoch [128/150] Train Loss: 0.4284, Train Acc: 79.71% | Val Loss: 0.5244, Val Acc: 75.13%\n",
      "Epoch [129/150] Train Loss: 0.4468, Train Acc: 78.80% | Val Loss: 0.5297, Val Acc: 74.98%\n",
      "Epoch [130/150] Train Loss: 0.4423, Train Acc: 78.58% | Val Loss: 0.5511, Val Acc: 74.44%\n",
      "Epoch [131/150] Train Loss: 0.4414, Train Acc: 78.54% | Val Loss: 0.5379, Val Acc: 74.80%\n",
      "Epoch [132/150] Train Loss: 0.4314, Train Acc: 79.66% | Val Loss: 0.5435, Val Acc: 74.78%\n",
      "Epoch [133/150] Train Loss: 0.4347, Train Acc: 79.56% | Val Loss: 0.5354, Val Acc: 74.34%\n",
      "Epoch [134/150] Train Loss: 0.4427, Train Acc: 78.99% | Val Loss: 0.5332, Val Acc: 74.58%\n",
      "Epoch [135/150] Train Loss: 0.4421, Train Acc: 78.44% | Val Loss: 0.5492, Val Acc: 74.48%\n",
      "Epoch [136/150] Train Loss: 0.4409, Train Acc: 79.19% | Val Loss: 0.5356, Val Acc: 75.00%\n",
      "Epoch [137/150] Train Loss: 0.4386, Train Acc: 78.80% | Val Loss: 0.5348, Val Acc: 74.98%\n",
      "Epoch [138/150] Train Loss: 0.4309, Train Acc: 79.54% | Val Loss: 0.5449, Val Acc: 74.60%\n",
      "Epoch [139/150] Train Loss: 0.4247, Train Acc: 79.81% | Val Loss: 0.5644, Val Acc: 74.10%\n",
      "Epoch [140/150] Train Loss: 0.4340, Train Acc: 79.91% | Val Loss: 0.5277, Val Acc: 74.56%\n",
      "Epoch [141/150] Train Loss: 0.4279, Train Acc: 79.66% | Val Loss: 0.5516, Val Acc: 73.41%\n",
      "Epoch [142/150] Train Loss: 0.4453, Train Acc: 78.39% | Val Loss: 0.5507, Val Acc: 74.76%\n",
      "Epoch [143/150] Train Loss: 0.4408, Train Acc: 79.19% | Val Loss: 0.5317, Val Acc: 75.07%\n",
      "Epoch [144/150] Train Loss: 0.4232, Train Acc: 80.44% | Val Loss: 0.5251, Val Acc: 75.17%\n",
      "Epoch [145/150] Train Loss: 0.4336, Train Acc: 79.09% | Val Loss: 0.5248, Val Acc: 75.39%\n",
      "Epoch [146/150] Train Loss: 0.4304, Train Acc: 79.09% | Val Loss: 0.5557, Val Acc: 73.83%\n",
      "Epoch [147/150] Train Loss: 0.4210, Train Acc: 80.05% | Val Loss: 0.5488, Val Acc: 73.59%\n",
      "Epoch [148/150] Train Loss: 0.4205, Train Acc: 79.68% | Val Loss: 0.5405, Val Acc: 75.69%\n",
      "Epoch [149/150] Train Loss: 0.4370, Train Acc: 78.80% | Val Loss: 0.5425, Val Acc: 74.44%\n",
      "Epoch [150/150] Train Loss: 0.4160, Train Acc: 80.67% | Val Loss: 0.5417, Val Acc: 75.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Binary Cross-Entropy loss (since final layer uses sigmoid)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 150\n",
    "early_stopping = EarlyStopping(patience=150)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #print(f\"{epoch} of {num_epochs}\")\n",
    "    # === Training ===\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move data to GPU\n",
    "        images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        preds = (outputs > 0.5).float()\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "    \n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    avg_val_accuracy = 100*val_correct/val_total\n",
    "    avg_accuracy = 100*train_correct/train_total\n",
    "    avg_loss = train_loss/len(train_loader)\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_loss:.4f}, \"\n",
    "          f\"Train Acc: {avg_accuracy:.2f}% | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Acc: {avg_val_accuracy:.2f}%\")\n",
    "    \n",
    "    #avg_val_loss = val_loss / len(test_loader)\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Val Loss = {avg_val_loss:.4f}\")\n",
    "    early_stopping(avg_accuracy, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Restore best model weights\n",
    "model.load_state_dict(early_stopping.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e5f9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current timestamp (e.g., 2025-08-29_15-42-10)\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# Save model with timestamp in filename\n",
    "torch.save(model.state_dict(), f'{destination_path}\\\\model_weights_{timestamp}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac8f668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Truck\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # match training normalization\n",
    "])\n",
    "\n",
    "# Load image\n",
    "img_path = destination_path + r\"\\what.jpeg\"\n",
    "#print(img_path)\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image = transform(image).unsqueeze(0)  # add batch dimension (1, 3, 64, 64)\n",
    "\n",
    "# Send to same device as model\n",
    "image = image.to(device)\n",
    "\n",
    "# Prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    pred = (output > 0.5).float().item()  # sigmoid threshold 0.5\n",
    "\n",
    "# Map prediction back to class label\n",
    "# Same as training_set.class_indices in Keras\n",
    "class_indices = train_dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "prediction = idx_to_class[int(pred)]\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "765ecc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Users\\fejio\\Downloads\\KC\\pred\n",
      "\n",
      "Checking TRAIN folder...\n",
      "\n",
      "Checking VALID folder...\n",
      "\n",
      "Overall Accuracy on PRED: 8166/10168 = 80.31%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define same transform as training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "pred_dir = destination_path + r\"\\pred\"\n",
    "print(pred_dir)\n",
    "\n",
    "# Same mapping as training\n",
    "class_indices = train_dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "# Loop over train/ and valid/ subfolders\n",
    "for split in [\"train\", \"valid\"]:\n",
    "    split_dir = os.path.join(pred_dir, split)\n",
    "    print(f\"\\nChecking {split.upper()} folder...\")\n",
    "\n",
    "    # Loop over class subfolders (car, truck)\n",
    "    for class_name in os.listdir(split_dir):\n",
    "        class_dir = os.path.join(split_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                # Ground truth = folder name\n",
    "                true_label = class_name.lower()\n",
    "\n",
    "                # Load image\n",
    "                img_path = os.path.join(class_dir, fname)\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "                # Predict\n",
    "                with torch.no_grad():\n",
    "                    output = model(image)\n",
    "                    pred = (output > 0.5).float().item()\n",
    "                    pred_label = idx_to_class[int(pred)].lower()\n",
    "\n",
    "                # Compare\n",
    "                is_correct = (pred_label == true_label)\n",
    "                correct += int(is_correct)\n",
    "                total += 1\n",
    "\n",
    "                #print(f\"{fname} -> Predicted: {pred_label}, True: {true_label}, Correct: {is_correct}\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy on PRED: {correct}/{total} = {100*correct/total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
